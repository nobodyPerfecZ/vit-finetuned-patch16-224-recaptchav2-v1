{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45b49efb",
   "metadata": {},
   "source": [
    "## Prepare Dataset with HuggingFace ðŸ¤—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d6c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import IterableDataset, load_dataset\n",
    "from transformers import ViTImageProcessor\n",
    "\n",
    "\n",
    "def get_datasets(type: str) -> IterableDataset:\n",
    "    # Load the dataset\n",
    "    dataset = load_dataset(\"nobodyPerfecZ/recaptchav2-dataset\")\n",
    "\n",
    "    # Load the feature extractor\n",
    "    processor = ViTImageProcessor.from_pretrained(\n",
    "        pretrained_model_name_or_path=\"google/vit-base-patch16-224\",\n",
    "    )\n",
    "\n",
    "    # Preprocess the dataset with the feature extractor\n",
    "    dataset = (\n",
    "        dataset.map(\n",
    "            lambda example: processor(images=example[\"image\"]),\n",
    "            batched=True,\n",
    "        )\n",
    "        .rename_columns({\"pixel_values\": \"inputs\"})\n",
    "        .with_format(type, columns=[\"inputs\", \"labels\"])\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a889449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_datasets(type=\"jax\")\n",
    "dataset = get_datasets(type=\"pt\")\n",
    "# dataset = get_datasets(type=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1556f8ad",
   "metadata": {},
   "source": [
    "## Fine-Tuning of Pre-Trained Model with HuggingFace ðŸ¤—\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9458e8c",
   "metadata": {},
   "source": [
    "### With Flax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef2ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FlaxViTForImageClassification\n",
    "\n",
    "# Fine-tune ViT model on a custom dataset\n",
    "model = FlaxViTForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"google/vit-base-patch16-224\",\n",
    "    num_labels=5,\n",
    "    id2label={\n",
    "        0: \"bicycle\",\n",
    "        1: \"bus\",\n",
    "        2: \"car\",\n",
    "        3: \"crosswalk\",\n",
    "        4: \"hydrant\",\n",
    "    },\n",
    "    label2id={\n",
    "        \"bicycle\": 0,\n",
    "        \"bus\": 1,\n",
    "        \"car\": 2,\n",
    "        \"crosswalk\": 3,\n",
    "        \"hydrant\": 4,\n",
    "    },\n",
    "    ignore_mismatched_sizes=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00950959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import chex\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from flax.training.train_state import TrainState\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_train_state(\n",
    "    model: FlaxViTForImageClassification,\n",
    "    max_grad_norm: float,\n",
    "    learning_rate: float,\n",
    "    b1: float,\n",
    "    b2: float,\n",
    "    eps: float,\n",
    "):\n",
    "    return TrainState.create(\n",
    "        apply_fn=model.__call__,\n",
    "        params=model.params,\n",
    "        tx=optax.chain(\n",
    "            optax.clip_by_global_norm(max_norm=max_grad_norm),\n",
    "            optax.adamw(learning_rate=learning_rate, b1=b1, b2=b2, eps=eps),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(state: TrainState, batch: Dict[str, chex.Array]):\n",
    "    def loss_fn(params):\n",
    "        logits = state.apply_fn(batch[\"inputs\"], params=params, train=True).logits\n",
    "        loss = optax.sigmoid_binary_cross_entropy(logits, batch[\"labels\"]).mean()\n",
    "        return loss\n",
    "\n",
    "    grads = jax.grad(loss_fn)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def eval_step(state: TrainState, batch: Dict[str, chex.Array]) -> Tuple[float, float]:\n",
    "    def accuracy(logits: chex.Array, labels: chex.Array):\n",
    "        probabilities = jax.nn.sigmoid(logits)\n",
    "        predictions = (probabilities >= 0.5).astype(jnp.int32)\n",
    "        return jnp.all(predictions == labels, axis=-1).mean()\n",
    "\n",
    "    def hamming_accuracy(logits: chex.Array, labels: chex.Array):\n",
    "        probabilities = jax.nn.sigmoid(logits)\n",
    "        predictions = (probabilities >= 0.5).astype(jnp.int32)\n",
    "        return 1 - jnp.logical_xor(predictions, labels).mean()\n",
    "\n",
    "    logits = state.apply_fn(batch[\"inputs\"], params=state.params, train=True).logits\n",
    "    return accuracy(logits, batch[\"labels\"]), hamming_accuracy(logits, batch[\"labels\"])\n",
    "\n",
    "\n",
    "def train(\n",
    "    state: TrainState,\n",
    "    train_dataset: IterableDataset,\n",
    "    eval_dataset: IterableDataset,\n",
    "    num_train_epochs: int,\n",
    "    batch_size: int,\n",
    "):\n",
    "    metrics = {\n",
    "        \"accuracy\": jnp.zeros((num_train_epochs,)),\n",
    "        \"hamming_accuracy\": jnp.zeros((num_train_epochs,)),\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_train_epochs):\n",
    "        num_train_batches = len(train_dataset) // batch_size\n",
    "        train_total = num_train_batches * batch_size\n",
    "        with tqdm(total=train_total, desc=f\"Training Epoch {epoch+1}\") as pbar:\n",
    "            for batch in train_dataset.iter(\n",
    "                batch_size=batch_size, drop_last_batch=True\n",
    "            ):\n",
    "                state = train_step(state, batch)\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "        num_eval_batches = len(eval_dataset) // batch_size\n",
    "        eval_total = num_eval_batches * batch_size\n",
    "        with tqdm(total=eval_total, desc=f\"Evaluating Epoch {epoch+1}\") as pbar:\n",
    "            for batch in eval_dataset.iter(batch_size=batch_size, drop_last_batch=True):\n",
    "                accuracy, hamming_accuracy = eval_step(state, batch)\n",
    "                metrics[\"accuracy\"] = (\n",
    "                    metrics[\"accuracy\"]\n",
    "                    .at[epoch]\n",
    "                    .set(metrics[\"accuracy\"][epoch] + accuracy)\n",
    "                )\n",
    "                metrics[\"hamming_accuracy\"] = (\n",
    "                    metrics[\"hamming_accuracy\"]\n",
    "                    .at[epoch]\n",
    "                    .set(metrics[\"hamming_accuracy\"][epoch] + hamming_accuracy)\n",
    "                )\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "        metrics[\"accuracy\"] = (\n",
    "            metrics[\"accuracy\"]\n",
    "            .at[epoch]\n",
    "            .set(metrics[\"accuracy\"][epoch] / num_eval_batches)\n",
    "        )\n",
    "        metrics[\"hamming_accuracy\"] = (\n",
    "            metrics[\"hamming_accuracy\"]\n",
    "            .at[epoch]\n",
    "            .set(metrics[\"hamming_accuracy\"][epoch] / num_eval_batches)\n",
    "        )\n",
    "\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_grad_norm = 1.0\n",
    "learning_rate = 5e-5\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "eps = 1e-8\n",
    "\n",
    "# Training Hyperparmeters\n",
    "num_train_epochs = 2\n",
    "batch_size = 32\n",
    "\n",
    "train_state = create_train_state(\n",
    "    model=model,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    learning_rate=learning_rate,\n",
    "    b1=b1,\n",
    "    b2=b2,\n",
    "    eps=eps,\n",
    ")\n",
    "final_state, metrics = train(\n",
    "    state=train_state,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "model.params = final_state.params\n",
    "model.save_pretrained(\"./vit-finetuned-patch16-224-recaptchav2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae1b73e",
   "metadata": {},
   "source": [
    "### With PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0db7365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "\n",
    "# Fine-tune ViT model on a custom dataset\n",
    "model = ViTForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"google/vit-base-patch16-224\",\n",
    "    num_labels=5,\n",
    "    id2label={\n",
    "        0: \"bicycle\",\n",
    "        1: \"bus\",\n",
    "        2: \"car\",\n",
    "        3: \"crosswalk\",\n",
    "        4: \"hydrant\",\n",
    "    },\n",
    "    label2id={\n",
    "        \"bicycle\": 0,\n",
    "        \"bus\": 1,\n",
    "        \"car\": 2,\n",
    "        \"crosswalk\": 3,\n",
    "        \"hydrant\": 4,\n",
    "    },\n",
    "    ignore_mismatched_sizes=True,\n",
    ").to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f473f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from flax.training.train_state import TrainState\n",
    "from torch.optim import AdamW, Optimizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainState:\n",
    "    apply_fn: Callable\n",
    "    params: Dict[str, torch.Tensor]\n",
    "    tx: Optimizer\n",
    "    max_grad_norm: float\n",
    "\n",
    "\n",
    "def create_train_state(\n",
    "    model: ViTForImageClassification,\n",
    "    max_grad_norm: float,\n",
    "    learning_rate: float,\n",
    "    b1: float,\n",
    "    b2: float,\n",
    "    eps: float,\n",
    "):\n",
    "    return TrainState(\n",
    "        apply_fn=model.__call__,\n",
    "        params=model.parameters(),\n",
    "        tx=AdamW(model.parameters(), lr=learning_rate, betas=(b1, b2), eps=eps),\n",
    "        max_grad_norm=max_grad_norm,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_step(state: TrainState, batch: Dict[str, torch.Tensor]):\n",
    "    def loss_fn():\n",
    "        logits = state.apply_fn(batch[\"inputs\"]).logits\n",
    "        loss = F.binary_cross_entropy_with_logits(\n",
    "            logits, batch[\"labels\"].to(torch.float32)\n",
    "        ).mean()\n",
    "        return loss\n",
    "\n",
    "    state.tx.zero_grad()\n",
    "    loss = loss_fn()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(state.params, state.max_grad_norm)\n",
    "    state.tx.step()\n",
    "    return state\n",
    "\n",
    "\n",
    "def eval_step(state: TrainState, batch: Dict[str, torch.Tensor]) -> Tuple[float, float]:\n",
    "    def accuracy(logits: torch.Tensor, labels: torch.Tensor):\n",
    "        probabilities = F.sigmoid(logits)\n",
    "        predictions = (probabilities >= 0.5).to(torch.int32)\n",
    "        return (\n",
    "            torch.all(predictions == labels, dim=-1)\n",
    "            .to(torch.float32)\n",
    "            .mean()\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "    def hamming_accuracy(logits: torch.Tensor, labels: torch.Tensor):\n",
    "        probabilities = F.sigmoid(logits)\n",
    "        predictions = (probabilities >= 0.5).to(torch.int32)\n",
    "        return (\n",
    "            1\n",
    "            - torch.logical_xor(predictions, labels)\n",
    "            .to(torch.float32)\n",
    "            .mean()\n",
    "            .detach()\n",
    "            .cpu()\n",
    "            .numpy()\n",
    "        )\n",
    "\n",
    "    logits = state.apply_fn(batch[\"inputs\"]).logits\n",
    "    return accuracy(logits, batch[\"labels\"]), hamming_accuracy(logits, batch[\"labels\"])\n",
    "\n",
    "\n",
    "def train(\n",
    "    state: TrainState,\n",
    "    train_dataset: IterableDataset,\n",
    "    eval_dataset: IterableDataset,\n",
    "    num_train_epochs: int,\n",
    "    batch_size: int,\n",
    "):\n",
    "    metrics = {\n",
    "        \"accuracy\": np.zeros((num_train_epochs,)),\n",
    "        \"hamming_accuracy\": np.zeros((num_train_epochs,)),\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_train_epochs):\n",
    "        model.train()\n",
    "        num_train_batches = len(train_dataset) // batch_size\n",
    "        train_total = num_train_batches * batch_size\n",
    "        with tqdm(total=train_total, desc=f\"Training Epoch {epoch+1}\") as pbar:\n",
    "            for batch in train_dataset.iter(\n",
    "                batch_size=batch_size, drop_last_batch=True\n",
    "            ):\n",
    "                batch[\"inputs\"] = batch[\"inputs\"].to(device=\"cuda\")\n",
    "                batch[\"labels\"] = batch[\"labels\"].to(device=\"cuda\")\n",
    "                state = train_step(state, batch)\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        num_eval_batches = len(eval_dataset) // batch_size\n",
    "        eval_total = num_eval_batches * batch_size\n",
    "        with tqdm(total=eval_total, desc=f\"Evaluating Epoch {epoch+1}\") as pbar:\n",
    "            for batch in eval_dataset.iter(batch_size=batch_size, drop_last_batch=True):\n",
    "                batch[\"inputs\"] = batch[\"inputs\"].to(device=\"cuda\")\n",
    "                batch[\"labels\"] = batch[\"labels\"].to(device=\"cuda\")\n",
    "                accuracy, hamming_accuracy = eval_step(state, batch)\n",
    "                metrics[\"accuracy\"][epoch] += accuracy\n",
    "                metrics[\"hamming_accuracy\"][epoch] += hamming_accuracy\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "        metrics[\"accuracy\"][epoch] /= num_eval_batches\n",
    "        metrics[\"hamming_accuracy\"][epoch] /= num_eval_batches\n",
    "\n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_grad_norm = 1.0\n",
    "learning_rate = 5e-5\n",
    "b1 = 0.9\n",
    "b2 = 0.999\n",
    "eps = 1e-8\n",
    "\n",
    "# Training Hyperparmeters\n",
    "num_train_epochs = 2\n",
    "batch_size = 32\n",
    "\n",
    "train_state = create_train_state(\n",
    "    model=model,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    learning_rate=learning_rate,\n",
    "    b1=b1,\n",
    "    b2=b2,\n",
    "    eps=eps,\n",
    ")\n",
    "final_state, metrics = train(\n",
    "    state=train_state,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "model.save_pretrained(\"./vit-finetuned-patch16-224-recaptchav2\")\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c5ce7f",
   "metadata": {},
   "source": [
    "## Safe Model from PyTorch to Flax with HuggingFace ðŸ¤—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740dd91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import FlaxViTForImageClassification\n",
    "\n",
    "model = FlaxViTForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"./vit-finetuned-patch16-224-recaptchav2-v1\",\n",
    "    from_pt=True,\n",
    ")\n",
    "model.save_pretrained(\"./vit-finetuned-patch16-224-recaptchav2-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37015e0a",
   "metadata": {},
   "source": [
    "## Safe Model from PyTorch to TensorFlow with HuggingFace ðŸ¤—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed7eabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFViTForImageClassification\n",
    "\n",
    "model = TFViTForImageClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=\"./vit-finetuned-patch16-224-recaptchav2-v1\",\n",
    "    from_pt=True,\n",
    ")\n",
    "model.save_pretrained(\"./vit-finetuned-patch16-224-recaptchav2-v1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recaptchav2-solver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
